from typing import Annotated, Dict, Any
from typing_extensions import TypedDict # For Python < 3.9 compatibility with add_messages if needed by LangGraph version

from langgraph.graph.message import add_messages # For IdiomaticState
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage # Added SystemMessage

# To be imported from .app (once app.py defines them and they are initialized in run_app)
# from .app import llm_with_tools, app_config

# Imports from within the package
from .utils import display, Markdown, save_user_data
# We expect IdiomaticConfig to be defined in config.py for type hinting app_config if needed locally
# from .config import IdiomaticConfig

# Placeholder for llm_with_tools and app_config that will be imported from app.py
# These will be populated by app.run_app()
llm_with_tools = None
app_config = None


# Agent Workflow State Definition
class IdiomaticState(TypedDict):
    messages: Annotated[list, add_messages]
    name: str
    user_level: str
    category: str
    score: int
    history: list[str]
    repetition_schedule: Dict[str, Any] # More specific type can be added if known
    finished: bool
    last_question: Dict[str, Any] | None


# Orchestration LLM System Prompt
IDIOMATIC_BOT_SYSINT_TEMPLATE = (
  "You are Idiomatic, a friendly and intelligent English language tutor designed to help non-native speakers master idioms through interactive learning. "
  "Your style is warm, supportive, and concise. You adapt to natural language and understand user intent even when it's not phrased exactly. "
  "Your goals: "
  " - Teach idioms through multiple choice questions generated by the system. "
  " - **You MUST use the provided tools when the user's intent matches.** Specifically: "
  "   * User asks for score ('How am I doing?', 'What's my score?'): **MUST call `show_score` tool.** The current score is available in the state. "
  "   * User asks for explanation of the last question ('explain', 'why?', 'explain that'): **MUST call `explain_last_question` tool.** The idiom is available in the state's last_question. "
  "   * User asks to lookup or define an idiom ('What does X mean?', 'lookup Y', 'idiom for Z?'): **MUST call `lookup_idiom` tool** with the user's query. "
  "   * User wants to quit ('Stop', 'I'm done', 'quit', 'exit'): **MUST call `quit_session` tool.** "
  " - Do NOT invent functionality or apologize for missing tools. The tools ARE available. "
  " - Do NOT call tools unnecessarily. If the user is just chatting or providing a quiz answer (a, b, c, d), respond naturally or let the workflow handle the answer. "
  " - Be flexible, encouraging, and gently correct users when needed. "
  "\n\n"
  # "Current Score: {score}. Last Question Idiom: {last_idiom}." # This will be formatted dynamically
)

def chatbot_node(state: IdiomaticState) -> IdiomaticState:
    """Handles initial setup, invokes LLM for routing/chat/tools, and checks for quit signal."""
    from .app import llm_with_tools as runtime_llm_with_tools, app_config as runtime_app_config

    if not runtime_llm_with_tools or not runtime_app_config:
        raise RuntimeError("llm_with_tools or app_config not initialized in app.py")

    # 1. Initial Setup
    if not state.get("name"):
        print("--- Initial Setup (from agent.py) ---")
        user_name = runtime_app_config.user_name or input("ðŸ‘‹ Welcome to Idiomatic! What's your name? ")

        level_choice = runtime_app_config.user_level
        if not level_choice:
            level_input = input("Skill level (a) beginner / (b) intermediate / (c) advanced [default: b]: ").strip().lower() or "b"
            level_map = {'a': 'beginner', 'b': 'intermediate', 'c': 'advanced'}
            level_choice = level_map.get(level_input, 'intermediate')

        category = runtime_app_config.idiom_category or input(f"Preferred idiom category (e.g., business, animals, food) [default: general]: ") or "general"

        state.update({
            "name": user_name,
            "user_level": level_choice,
            "category": category,
            "messages": [AIMessage(content=f"Hello {user_name}! ðŸ‘‹ Let's start with some {category} idioms at the {level_choice} level. I'll ask you multiple-choice questions. You can also ask me to 'explain', show your 'score', 'lookup' an idiom, or 'quit'.")]
        })
        display(Markdown(state['messages'][-1].content))
        # Note: app_config is not directly mutable here if it's just imported.
        # If these prompted values need to update the config instance itself, run_app would need to handle that.
        # For now, they update the state, which is used by the app.
        return state

    # 2. Process Last Message
    last_message = state["messages"][-1] if state["messages"] else None

    if isinstance(last_message, ToolMessage) and last_message.content == "QUIT_SESSION_SIGNAL":
        print("--- Quit Signal Received by Chatbot (from agent.py) ---")
        final_message = "ðŸ‘‹ Thanks for learning with Idiomatic! Your progress is saved."
        state["messages"].append(AIMessage(content=final_message))
        display(Markdown(final_message))
        state["finished"] = True
        save_user_data(runtime_app_config, state)
        return state

    try:
        print("--- Invoking LLM with Tools (Chatbot Node from agent.py) ---")
        current_score = state.get("score", 0)
        last_idiom_val = state.get("last_question", {}).get("idiom", "N/A") if state.get("last_question") else "N/A"

        formatted_sys_prompt = IDIOMATIC_BOT_SYSINT_TEMPLATE + f"\nCurrent Score: {current_score}. Last Question Idiom: {last_idiom_val}."

        response = runtime_llm_with_tools.invoke(
            [SystemMessage(content=formatted_sys_prompt)] + state["messages"]
        )
        state["messages"].append(response)

        if not response.tool_calls:
            display(Markdown(f"**Idiomatic:** {response.content}"))

    except Exception as e:
        print(f"Error invoking LLM in chatbot_node (agent.py): {e}")
        error_msg = "Sorry, I encountered an error. Please try again."
        state["messages"].append(AIMessage(content=error_msg))
        display(Markdown(error_msg))
    return state

def get_user_input(state: IdiomaticState) -> IdiomaticState:
    """Prompts the user for input and adds it as a HumanMessage."""
    print("--- Waiting for User Input (from agent.py) ---")
    prompt_message = "Your answer (a/b/c/d) or command: \n"
    user_input_text = input(prompt_message).strip()
    state["messages"].append(HumanMessage(content=user_input_text))
    return state
